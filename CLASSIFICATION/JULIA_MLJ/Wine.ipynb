{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "This notebook explores classification with MLJ, in particular with KNN and Multiclass logistic regression. \n",
                "\n",
                "The notebook is more oriented to learning Julia and MLJ than inspecting the data or the results. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "source": [
                "# NOTEBOOK SETTINGS ------\n",
                "d_packages= false # false \n",
                "# ENV ------\n",
                "versioninfo()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Julia Version 1.6.1\n",
                        "Commit 6aaedecc44 (2021-04-23 05:59 UTC)\n",
                        "Platform Info:\n",
                        "  OS: Linux (x86_64-pc-linux-gnu)\n",
                        "  CPU: AMD Ryzen 5 5600X 6-Core Processor\n",
                        "  WORD_SIZE: 64\n",
                        "  LIBM: libopenlibm\n",
                        "  LLVM: libLLVM-11.0.1 (ORCJIT, generic)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "# GET PACKAGES ------\n",
                "if d_packages\n",
                "    using Pkg\n",
                "    Pkg.add(\"HTTP\")\n",
                "    Pkg.add(\"MLJ\")\n",
                "    Pkg.add(\"PyPlot\")\n",
                "    Pkg.add(\"DataFrames\")\n",
                "    Pkg.add(\"UrlDownload\")\n",
                "    Pkg.add(\"NearestNeighborModels\")\n",
                "    Pkg.add(\"MLJLinearModels\")\n",
                "end"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# PACKAGES ------\n",
                "using HTTP\n",
                "using MLJ\n",
                "using PyPlot\n",
                "import DataFrames: DataFrame, describe\n",
                "using UrlDownload\n",
                "\n",
                "# GET DATA ------\n",
                "\n",
                "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
                "header = [\"Class\", \"Alcool\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\",\n",
                "          \"Magnesium\", \"Total phenols\", \"Flavanoids\",\n",
                "          \"Nonflavanoid phenols\", \"Proanthcyanins\", \"Color intensity\",\n",
                "          \"Hue\", \"OD280/OD315 of diluted wines\", \"Proline\"]\n",
                "data = urldownload(url, true, format=:CSV, header=header);"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "WARNING: could not import DataFrames.countmap into Main\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "df = DataFrame(data)\n",
                "describe(df)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\u001b[1m14×7 DataFrame\u001b[0m\n",
                            "\u001b[1m Row \u001b[0m│\u001b[1m variable                     \u001b[0m\u001b[1m mean       \u001b[0m\u001b[1m min    \u001b[0m\u001b[1m median  \u001b[0m\u001b[1m max     \u001b[0m\u001b[1m nmi\u001b[0m ⋯\n",
                            "\u001b[1m     \u001b[0m│\u001b[90m Symbol                       \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Real   \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Real    \u001b[0m\u001b[90m Int\u001b[0m ⋯\n",
                            "─────┼──────────────────────────────────────────────────────────────────────────\n",
                            "   1 │ Class                           1.9382      1       2.0       3         ⋯\n",
                            "   2 │ Alcool                         13.0006     11.03   13.05     14.83\n",
                            "   3 │ Malic acid                      2.33635     0.74    1.865     5.8\n",
                            "   4 │ Ash                             2.36652     1.36    2.36      3.23\n",
                            "   5 │ Alcalinity of ash              19.4949     10.6    19.5      30.0       ⋯\n",
                            "   6 │ Magnesium                      99.7416     70      98.0     162\n",
                            "   7 │ Total phenols                   2.29511     0.98    2.355     3.88\n",
                            "   8 │ Flavanoids                      2.02927     0.34    2.135     5.08\n",
                            "   9 │ Nonflavanoid phenols            0.361854    0.13    0.34      0.66      ⋯\n",
                            "  10 │ Proanthcyanins                  1.5909      0.41    1.555     3.58\n",
                            "  11 │ Color intensity                 5.05809     1.28    4.69     13.0\n",
                            "  12 │ Hue                             0.957449    0.48    0.965     1.71\n",
                            "  13 │ OD280/OD315 of diluted wines    2.61169     1.27    2.78      4.0       ⋯\n",
                            "  14 │ Proline                       746.893     278     673.5    1680\n",
                            "\u001b[36m                                                               2 columns omitted\u001b[0m"
                        ],
                        "text/latex": [
                            "\\begin{tabular}{r|ccccccc}\n",
                            "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
                            "\t\\hline\n",
                            "\t& Symbol & Float64 & Real & Float64 & Real & Int64 & DataType\\\\\n",
                            "\t\\hline\n",
                            "\t1 & Class & 1.9382 & 1 & 2.0 & 3 & 0 & Int64 \\\\\n",
                            "\t2 & Alcool & 13.0006 & 11.03 & 13.05 & 14.83 & 0 & Float64 \\\\\n",
                            "\t3 & Malic acid & 2.33635 & 0.74 & 1.865 & 5.8 & 0 & Float64 \\\\\n",
                            "\t4 & Ash & 2.36652 & 1.36 & 2.36 & 3.23 & 0 & Float64 \\\\\n",
                            "\t5 & Alcalinity of ash & 19.4949 & 10.6 & 19.5 & 30.0 & 0 & Float64 \\\\\n",
                            "\t6 & Magnesium & 99.7416 & 70 & 98.0 & 162 & 0 & Int64 \\\\\n",
                            "\t7 & Total phenols & 2.29511 & 0.98 & 2.355 & 3.88 & 0 & Float64 \\\\\n",
                            "\t8 & Flavanoids & 2.02927 & 0.34 & 2.135 & 5.08 & 0 & Float64 \\\\\n",
                            "\t9 & Nonflavanoid phenols & 0.361854 & 0.13 & 0.34 & 0.66 & 0 & Float64 \\\\\n",
                            "\t10 & Proanthcyanins & 1.5909 & 0.41 & 1.555 & 3.58 & 0 & Float64 \\\\\n",
                            "\t11 & Color intensity & 5.05809 & 1.28 & 4.69 & 13.0 & 0 & Float64 \\\\\n",
                            "\t12 & Hue & 0.957449 & 0.48 & 0.965 & 1.71 & 0 & Float64 \\\\\n",
                            "\t13 & OD280/OD315 of diluted wines & 2.61169 & 1.27 & 2.78 & 4.0 & 0 & Float64 \\\\\n",
                            "\t14 & Proline & 746.893 & 278 & 673.5 & 1680 & 0 & Int64 \\\\\n",
                            "\\end{tabular}\n"
                        ],
                        "text/html": [
                            "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Float64</th><th>Real</th><th>Float64</th><th>Real</th><th>Int64</th><th>DataType</th></tr></thead><tbody><p>14 rows × 7 columns</p><tr><th>1</th><td>Class</td><td>1.9382</td><td>1</td><td>2.0</td><td>3</td><td>0</td><td>Int64</td></tr><tr><th>2</th><td>Alcool</td><td>13.0006</td><td>11.03</td><td>13.05</td><td>14.83</td><td>0</td><td>Float64</td></tr><tr><th>3</th><td>Malic acid</td><td>2.33635</td><td>0.74</td><td>1.865</td><td>5.8</td><td>0</td><td>Float64</td></tr><tr><th>4</th><td>Ash</td><td>2.36652</td><td>1.36</td><td>2.36</td><td>3.23</td><td>0</td><td>Float64</td></tr><tr><th>5</th><td>Alcalinity of ash</td><td>19.4949</td><td>10.6</td><td>19.5</td><td>30.0</td><td>0</td><td>Float64</td></tr><tr><th>6</th><td>Magnesium</td><td>99.7416</td><td>70</td><td>98.0</td><td>162</td><td>0</td><td>Int64</td></tr><tr><th>7</th><td>Total phenols</td><td>2.29511</td><td>0.98</td><td>2.355</td><td>3.88</td><td>0</td><td>Float64</td></tr><tr><th>8</th><td>Flavanoids</td><td>2.02927</td><td>0.34</td><td>2.135</td><td>5.08</td><td>0</td><td>Float64</td></tr><tr><th>9</th><td>Nonflavanoid phenols</td><td>0.361854</td><td>0.13</td><td>0.34</td><td>0.66</td><td>0</td><td>Float64</td></tr><tr><th>10</th><td>Proanthcyanins</td><td>1.5909</td><td>0.41</td><td>1.555</td><td>3.58</td><td>0</td><td>Float64</td></tr><tr><th>11</th><td>Color intensity</td><td>5.05809</td><td>1.28</td><td>4.69</td><td>13.0</td><td>0</td><td>Float64</td></tr><tr><th>12</th><td>Hue</td><td>0.957449</td><td>0.48</td><td>0.965</td><td>1.71</td><td>0</td><td>Float64</td></tr><tr><th>13</th><td>OD280/OD315 of diluted wines</td><td>2.61169</td><td>1.27</td><td>2.78</td><td>4.0</td><td>0</td><td>Float64</td></tr><tr><th>14</th><td>Proline</td><td>746.893</td><td>278</td><td>673.5</td><td>1680</td><td>0</td><td>Int64</td></tr></tbody></table>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 4
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "From the describe table we can see that the target has 3 possible values. **Class** is the target column, it has a minimum of 1, a maximum of 3 and a median of 2. \n",
                "\n",
                "Since the column is of type Int, describe gives a mean. The mean is 1.93 indicating a slight imbalance that favorizes the first class but it is very light. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Create Dependent and independent variables \n",
                "\n",
                "MLJ has this function **unpack** that separates a DF in multiple parts. The parts are called __filters__, the set that satisfies a filter (yielding true) becomes a subset of columns. Since we know that the column __Class__ is teh target, we pass ==(:Class). I think col->true sets to true everything else (X). I find that  !=(:Class) may be more explicit. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "y, X = unpack(df, ==(:Class), col->true); # equivalent to y, X = unpack(df, ==(:Class), !=(:Class));"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now, as a common practice, we can check the schema. The Schema gives the types of the stored data and the MLJ interpretation in terms of scientific types. \n",
                "\n",
                "In this case, almost everything is **Continuous** and we have some **Count** columns (Magnesium and Proline). \n",
                "\n",
                "\n",
                "It's also nice to see the number of rows. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "schema(X)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "┌──────────────────────────────┬─────────┬────────────┐\n",
                            "│\u001b[22m _.names                      \u001b[0m│\u001b[22m _.types \u001b[0m│\u001b[22m _.scitypes \u001b[0m│\n",
                            "├──────────────────────────────┼─────────┼────────────┤\n",
                            "│ Alcool                       │ Float64 │ Continuous │\n",
                            "│ Malic acid                   │ Float64 │ Continuous │\n",
                            "│ Ash                          │ Float64 │ Continuous │\n",
                            "│ Alcalinity of ash            │ Float64 │ Continuous │\n",
                            "│ Magnesium                    │ Int64   │ Count      │\n",
                            "│ Total phenols                │ Float64 │ Continuous │\n",
                            "│ Flavanoids                   │ Float64 │ Continuous │\n",
                            "│ Nonflavanoid phenols         │ Float64 │ Continuous │\n",
                            "│ Proanthcyanins               │ Float64 │ Continuous │\n",
                            "│ Color intensity              │ Float64 │ Continuous │\n",
                            "│ Hue                          │ Float64 │ Continuous │\n",
                            "│ OD280/OD315 of diluted wines │ Float64 │ Continuous │\n",
                            "│ Proline                      │ Int64   │ Count      │\n",
                            "└──────────────────────────────┴─────────┴────────────┘\n",
                            "_.nrows = 178\n"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 6
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "methods(X)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "# 0 methods:"
                        ],
                        "text/html": [
                            "# 0 methods:<ul></ul>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Investigate a little"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "As we thought, Y has 3 possible values (1,2,3). "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "unique(y)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "3-element Vector{Int64}:\n",
                            " 1\n",
                            " 2\n",
                            " 3"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 8
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The column will be undestood as __Count__ type. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "scitype(y)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "AbstractVector{Count} (alias for AbstractArray{Count, 1})"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 9
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "But we should change that since it's more of a factor column rather than a numerical one. \n",
                "To change the scitype of a column we use the __coerce__ function. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "y= coerce(y, OrderedFactor);"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "scitype(y)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "AbstractVector{OrderedFactor{3}} (alias for AbstractArray{OrderedFactor{3}, 1})"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 11
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "So now we have an OrderedFactor with 3 classes. Great!"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "As for the predictors, we are dealing exclusively with continuous data. We should coerce Count to Continuous."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "X_coerced= coerce(X, Count=>Continuous); # following \"old\"=> \"new\"\n",
                "schema(X_coerced)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "┌──────────────────────────────┬─────────┬────────────┐\n",
                            "│\u001b[22m _.names                      \u001b[0m│\u001b[22m _.types \u001b[0m│\u001b[22m _.scitypes \u001b[0m│\n",
                            "├──────────────────────────────┼─────────┼────────────┤\n",
                            "│ Alcool                       │ Float64 │ Continuous │\n",
                            "│ Malic acid                   │ Float64 │ Continuous │\n",
                            "│ Ash                          │ Float64 │ Continuous │\n",
                            "│ Alcalinity of ash            │ Float64 │ Continuous │\n",
                            "│ Magnesium                    │ Float64 │ Continuous │\n",
                            "│ Total phenols                │ Float64 │ Continuous │\n",
                            "│ Flavanoids                   │ Float64 │ Continuous │\n",
                            "│ Nonflavanoid phenols         │ Float64 │ Continuous │\n",
                            "│ Proanthcyanins               │ Float64 │ Continuous │\n",
                            "│ Color intensity              │ Float64 │ Continuous │\n",
                            "│ Hue                          │ Float64 │ Continuous │\n",
                            "│ OD280/OD315 of diluted wines │ Float64 │ Continuous │\n",
                            "│ Proline                      │ Float64 │ Continuous │\n",
                            "└──────────────────────────────┴─────────┴────────────┘\n",
                            "_.nrows = 178\n"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 12
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "As this is not a deep dive in the problem, we will not check every column's distribution and correlation with the others. From the __describe__ table, we can see that columns values vary in magnitude (look at __Proline__ for ex). It might be a good idea to standardize the data, specially if we use a distance metrice or an iterative solver like gradient descent.  "
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Separate Train and Testing "
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "In MLJ, the partition usually is done for the indices rather than for the tables. Then the indices are used to subset the tables. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "### Separate Train and Testing ---\n",
                "train, test = partition(collect(eachindex(y)), 0.8, shuffle=true, rng=123); # Usual 20 % testing \n",
                "# eachindex is a safe 1:length(y)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "# Subset ---\n",
                "Xtrain = selectrows(X_coerced, train)\n",
                "Xtest = selectrows(X_coerced, test)\n",
                "ytrain = selectrows(y, train)\n",
                "ytest = selectrows(y, test);"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "We then define the models. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "# MODELS ---\n",
                "KNNC = @load KNNClassifier  # A nearest neighbors model \n",
                "MNC = @load MultinomialClassifier pkg=MLJLinearModels; # a logistic model for multiclass data \n",
                "\n",
                "KnnPipe = @pipeline(Standardizer(), KNNC())\n",
                "MnPipe = @pipeline(Standardizer(), MNC());"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "┌ Info: For silent loading, specify `verbosity=0`. \n",
                        "└ @ Main /root/.julia/packages/MLJModels/5itei/src/loading.jl:168\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "import NearestNeighborModels ✔\n",
                        "import MLJLinearModels ✔"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "┌ Info: For silent loading, specify `verbosity=0`. \n",
                        "└ @ Main /root/.julia/packages/MLJModels/5itei/src/loading.jl:168\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "As always, we wrap a model with a machine. Machine holds the parameters of a model."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "# MACHINES --- \n",
                "knn = machine(KnnPipe, Xtrain, ytrain)\n",
                "regression = machine(MnPipe, Xtrain, ytrain)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\u001b[34mMachine{Pipeline266,…} @929\u001b[39m trained 0 times; caches data\n",
                            "  args: \n",
                            "    1:\t\u001b[34mSource @592\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
                            "    2:\t\u001b[34mSource @716\u001b[39m ⏎ `AbstractVector{OrderedFactor{3}}`\n"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 16
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "As our models are __trained 0 times__, we call the fit method. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "# FITTING --- \n",
                "fit!(knn)\n",
                "fit!(regression)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "┌ Info: Training \u001b[34mMachine{Pipeline259,…} @627\u001b[39m.\n",
                        "└ @ MLJBase /root/.julia/packages/MLJBase/rN59G/src/machines.jl:354\n",
                        "┌ Info: Training \u001b[34mMachine{Standardizer,…} @759\u001b[39m.\n",
                        "└ @ MLJBase /root/.julia/packages/MLJBase/rN59G/src/machines.jl:354\n",
                        "┌ Info: Training \u001b[34mMachine{KNNClassifier,…} @028\u001b[39m.\n",
                        "└ @ MLJBase /root/.julia/packages/MLJBase/rN59G/src/machines.jl:354\n",
                        "┌ Info: Training \u001b[34mMachine{Pipeline266,…} @929\u001b[39m.\n",
                        "└ @ MLJBase /root/.julia/packages/MLJBase/rN59G/src/machines.jl:354\n",
                        "┌ Info: Training \u001b[34mMachine{Standardizer,…} @247\u001b[39m.\n",
                        "└ @ MLJBase /root/.julia/packages/MLJBase/rN59G/src/machines.jl:354\n",
                        "┌ Info: Training \u001b[34mMachine{MultinomialClassifier,…} @905\u001b[39m.\n",
                        "└ @ MLJBase /root/.julia/packages/MLJBase/rN59G/src/machines.jl:354\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\u001b[34mMachine{Pipeline266,…} @929\u001b[39m trained 1 time; caches data\n",
                            "  args: \n",
                            "    1:\t\u001b[34mSource @592\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
                            "    2:\t\u001b[34mSource @716\u001b[39m ⏎ `AbstractVector{OrderedFactor{3}}`\n"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 17
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Great that was fast. We can get the prediction calling the predict method. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "One thing to note is that the model gives a prediction for every class. The weights matrix of the model is then of shape (n_columns, classes). "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "predict(regression, Xtrain[1:3,:]) "
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "3-element MLJBase.UnivariateFiniteVector{OrderedFactor{3}, Int64, UInt32, Float64}:\n",
                            " UnivariateFinite{OrderedFactor{3}}(1=>0.993, 2=>0.00696, 3=>9.58e-5)\n",
                            " UnivariateFinite{OrderedFactor{3}}(1=>0.00551, 2=>0.994, 3=>2.81e-5)\n",
                            " UnivariateFinite{OrderedFactor{3}}(1=>1.0, 2=>2.65e-5, 3=>8.27e-5)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 18
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "W=fitted_params(regression)\n",
                "W[1].coefs"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "13-element Vector{Pair{Symbol, SubArray{Float64, 1, Matrix{Float64}, Tuple{Int64, Base.Slice{Base.OneTo{Int64}}}, true}}}:\n",
                            "                                :Alcool => [0.7440262558090187, -0.983628753301021, 0.23960249749200227]\n",
                            "                   Symbol(\"Malic acid\") => [0.1801466521718594, -0.3929356927714954, 0.21278904059963544]\n",
                            "                                   :Ash => [0.4109091488604062, -0.7643041885115611, 0.35339503965115504]\n",
                            "            Symbol(\"Alcalinity of ash\") => [-0.7928476360704427, 0.5965465593788984, 0.19630107669154379]\n",
                            "                             :Magnesium => [0.10296940790786051, -0.13595956522364963, 0.03299015731578979]\n",
                            "                Symbol(\"Total phenols\") => [0.1775501748972599, 0.18696576707637386, -0.3645159419736337]\n",
                            "                            :Flavanoids => [0.6010862996227639, 0.3344089580899755, -0.9354952577127393]\n",
                            "         Symbol(\"Nonflavanoid phenols\") => [-0.17596525958347306, 0.16472099831170142, 0.011244261271772183]\n",
                            "                        :Proanthcyanins => [0.25443071534423484, 0.06817338623604988, -0.322604101580285]\n",
                            "              Symbol(\"Color intensity\") => [0.11327932709782988, -0.8882228169252928, 0.7749434898274629]\n",
                            "                                   :Hue => [0.11517053560088353, 0.636260573591054, -0.7514311091919372]\n",
                            " Symbol(\"OD280/OD315 of diluted wines\") => [0.6717233828649596, 0.10623049205077618, -0.7779538749157358]\n",
                            "                               :Proline => [1.0476780301612947, -1.198705264171322, 0.15102723401002735]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 19
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "To take the argmax prediction from the 3 classes at eachrow, we use the predict_mode method. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "# PREDICT SOFTMAX --- \n",
                "knn_y_hat=predict_mode(knn, Xtrain)\n",
                "regression_y_hat=predict_mode(regression, Xtrain);"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "With these prediction we can know calculate several things, let's try accuracy and misclassification_rate"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "print(\"KNN MISCLASSIFICATION\")\n",
                "misclassification_rate(knn_y_hat, ytrain)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "KNN MISCLASSIFICATION"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "0.028169014084507043"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 21
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "print(\"REGRESSION MISCLASSIFICATION\")\n",
                "misclassification_rate(regression_y_hat, ytrain)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "REGRESSION MISCLASSIFICATION"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "0.0"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 22
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "So weirdly, the regression model did a perfect fit for the training set. The data seems to separate very well the classes. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### PREDICT TESTING SOFTMAX --- \n",
                "Now we make our prediction on the testing set. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "knn_y_test=predict_mode(knn, Xtest)\n",
                "regression_y_test=predict_mode(regression, Xtest);"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "print(\"[TEST] KNN MISCLASSIFICATION\")\n",
                "round(misclassification_rate(knn_y_test, ytest),sigdigits=3)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[TEST] KNN MISCLASSIFICATION"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "0.0278"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 24
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "print(\"[TEST] REGRESSION MISCLASSIFICATION\")\n",
                "round(misclassification_rate(regression_y_test, ytest), sigdigits=5)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[TEST] REGRESSION MISCLASSIFICATION"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "0.0"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 25
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Since the misclassification rate is 0, we should find a perfect accuracy. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "source": [
                "print(\"[TEST] REGRESSION ACCURACY\")\n",
                "accuracy(regression_y_test, ytest)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[TEST] REGRESSION ACCURACY"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "1.0"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 27
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "file_extension": ".jl",
            "name": "julia",
            "mimetype": "application/julia",
            "version": "1.6.1"
        },
        "kernelspec": {
            "name": "julia-1.6",
            "display_name": "Julia 1.6.1",
            "language": "julia"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}