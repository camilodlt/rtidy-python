{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter Tuning for Convolutional Neural Network",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOefOdgot1epb9h+KTKMjDa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camilodlt/rtidy-python/blob/main/Computer%20vision/CIFAR/Hyperparameter_Tuning_for_Convolutional_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVLbfpzKPXiE"
      },
      "source": [
        "# Hyperparameter Tuning for Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwANWGDRN01T"
      },
      "source": [
        "## What we'll be doing? \n",
        "\n",
        "- We want to implement two hyperparameters search methods (=> Grid search and random search) on our convolutional model trained on [CIFAR 10](https://github.com/camilodlt/rtidy-python/blob/main/Computer%20vision/CIFAR/1_Deep_Learning_Models_for_Image_Classification.ipynb). Our last model overfitted rapidly because of the model's capacity. Some parameter tunning might alleviate this issue. \n",
        "\n",
        "- We'll try to improve our previous results (65%-67% accuracy on testing set). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFpWS3vCPrBv",
        "outputId": "2e3db2db-993f-4102-f046-e94431be2b78"
      },
      "source": [
        "# SAME AS BEFORE ------\n",
        "# LOAD LIBS ------\n",
        "import tensorflow as tf \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "# TF VERSION ------\n",
        "print(\"TF VERSION: \",tf.version.VERSION)\n",
        "# PYTHON VERSION ------\n",
        "print(\"Python Version:\",sys.version)\n",
        "# LOAD DATA ------ \n",
        "# we can simplely use the tf.keras.datasets.cifar10.load_data API to load dataset\n",
        "(x_train, y_train), (x_test, y_test) =  tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Scale --- \n",
        "x_train= x_train.astype('float32')/255\n",
        "x_test= x_test.astype('float32')/255\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF VERSION:  2.6.0\n",
            "Python Version: 3.7.11 (default, Jul  3 2021, 18:01:19) \n",
            "[GCC 7.5.0]\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fCOcbQ7PUdc"
      },
      "source": [
        "## Grid search hyperparameter for Convolutional neural network\n",
        "\n",
        "This is going to be a greedy operation. I'll use our previous network (architecture held constant) but the number of CONV filters will vary. \n",
        "\n",
        "Only CONV filter will be variable. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp3MPUz5Nm60"
      },
      "source": [
        "# WRAP MODEL IN A FUNCTION ------ \n",
        "\"\"\"\n",
        "The only changing parameter is the convolutional layers filters \n",
        "Everything else is held constant\n",
        "\"\"\"\n",
        "def grid_search(settings:list):\n",
        "\n",
        "  # constant\n",
        "  inputs = tf.keras.Input(shape=(32,32,3,),name=\"Image_flatten\")\n",
        "\n",
        "  # variable\n",
        "  x= tf.keras.layers.Conv2D(settings[0],kernel_size=(3,3), name=\"First_CONV\")(inputs) # 32 FILTERS, 3*3 kernel boxes\n",
        "  # constant\n",
        "  x= tf.keras.layers.MaxPooling2D()(x) # default 2*2\n",
        "\n",
        "  # variable\n",
        "  x= tf.keras.layers.Conv2D(settings[1],kernel_size=(3,3), name=\"Second_CONV\")(x) # 64 FILTERS, 3*3 kernel boxes\n",
        "  # constant\n",
        "  x= tf.keras.layers.MaxPooling2D()(x) # default 2*2\n",
        "\n",
        "  # variable\n",
        "  x= tf.keras.layers.Conv2D(settings[2],kernel_size=(3,3), name=\"Third_CONV\")(x) # 64 FILTERS, 3*3 kernel boxes\n",
        "\n",
        "  # constant\n",
        "  x= tf.keras.layers.Flatten()(x)\n",
        "  # constant\n",
        "  x= tf.keras.layers.Dense(64, activation=\"relu\", name= \"Dense_1\")(x)\n",
        "  outputs = tf.keras.layers.Dense(10, activation=\"softmax\",name=\"output_Dense_2\")(x)\n",
        "    #* Model --- \n",
        "  model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"Cifar_10_CONV_model\")\n",
        "  # COMPILE MODEL --- \n",
        "  model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\", #Since we did not one hot encode y_train\n",
        "              metrics= [\"sparse_categorical_accuracy\"])\n",
        "  history_conv = model.fit(x_train, y_train, batch_size=64, epochs=20, validation_split=0.2,verbose=0)\n",
        "\n",
        "  return((history_conv.history['val_sparse_categorical_accuracy'],history_conv.history['val_loss'])) # return val accuracy at every epoch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkYFQRofmeaW"
      },
      "source": [
        "We know define our grid search. We use 16, 32, 48 and 64 filters for every conv layer. \n",
        "\n",
        "We take the cartesian product to try all possible combinations. This yields 64 combinations to try => 64 models to train. **Very greedy process**. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYWmGF5JRnQR",
        "outputId": "202a83b9-1c87-431f-8c96-4d2585fde3d1"
      },
      "source": [
        "# GRID SEARCH ------\n",
        "n_layers=3 # How many CONVS\n",
        "params= [] \n",
        "for layer in range(n_layers):\n",
        "  params.append(np.linspace(start=16, stop=64, num=4)) # 16, 32, 48, 64 \n",
        "\n",
        "from itertools import product\n",
        "params=list(product(*params)) # Cartesian product => all combinations 4*4*4\n",
        "print(\"Number of combinations to try :\", len(params))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of combinations to try : 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWhiNebxmxXK"
      },
      "source": [
        "We fit every model and save every validation accuracy history. \n",
        "\n",
        "For each model we print the maximum accuracy obtained, no matter the epoch. \n",
        "\n",
        "Results did not change much from the parameters we had already specified. Validation accuracy stayed rather similar for every model (between 65 and 68)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wyAvOq2Yjj_",
        "outputId": "d88ed131-e7d0-4a98-e1ba-7ef56e62254e"
      },
      "source": [
        "# RUN MODELS ------\n",
        "score=[]\n",
        "loss= []\n",
        "for i,param in enumerate(params):\n",
        "  print(f\"[TRYING SETTING N:{i}]\")\n",
        "  val_result,loss_result= grid_search(param)\n",
        "  print(f\"Max validation accuracy: {max(val_result)}\")\n",
        "  score.append(val_result)\n",
        "  loss.append(loss_result)\n",
        "print(\"END\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TRYING SETTING N:0]\n",
            "Max validation accuracy: 0.6574000120162964\n",
            "[TRYING SETTING N:1]\n",
            "Max validation accuracy: 0.6660000085830688\n",
            "[TRYING SETTING N:2]\n",
            "Max validation accuracy: 0.6658999919891357\n",
            "[TRYING SETTING N:3]\n",
            "Max validation accuracy: 0.6603000164031982\n",
            "[TRYING SETTING N:4]\n",
            "Max validation accuracy: 0.6747999787330627\n",
            "[TRYING SETTING N:5]\n",
            "Max validation accuracy: 0.6608999967575073\n",
            "[TRYING SETTING N:6]\n",
            "Max validation accuracy: 0.6577000021934509\n",
            "[TRYING SETTING N:7]\n",
            "Max validation accuracy: 0.675000011920929\n",
            "[TRYING SETTING N:8]\n",
            "Max validation accuracy: 0.6758999824523926\n",
            "[TRYING SETTING N:9]\n",
            "Max validation accuracy: 0.6692000031471252\n",
            "[TRYING SETTING N:10]\n",
            "Max validation accuracy: 0.671999990940094\n",
            "[TRYING SETTING N:11]\n",
            "Max validation accuracy: 0.6801999807357788\n",
            "[TRYING SETTING N:12]\n",
            "Max validation accuracy: 0.6783000230789185\n",
            "[TRYING SETTING N:13]\n",
            "Max validation accuracy: 0.6796000003814697\n",
            "[TRYING SETTING N:14]\n",
            "Max validation accuracy: 0.680899977684021\n",
            "[TRYING SETTING N:15]\n",
            "Max validation accuracy: 0.6812999844551086\n",
            "[TRYING SETTING N:16]\n",
            "Max validation accuracy: 0.6736999750137329\n",
            "[TRYING SETTING N:17]\n",
            "Max validation accuracy: 0.6721000075340271\n",
            "[TRYING SETTING N:18]\n",
            "Max validation accuracy: 0.6643999814987183\n",
            "[TRYING SETTING N:19]\n",
            "Max validation accuracy: 0.659500002861023\n",
            "[TRYING SETTING N:20]\n",
            "Max validation accuracy: 0.6675000190734863\n",
            "[TRYING SETTING N:21]\n",
            "Max validation accuracy: 0.6718999743461609\n",
            "[TRYING SETTING N:22]\n",
            "Max validation accuracy: 0.6723999977111816\n",
            "[TRYING SETTING N:23]\n",
            "Max validation accuracy: 0.6721000075340271\n",
            "[TRYING SETTING N:24]\n",
            "Max validation accuracy: 0.6690999865531921\n",
            "[TRYING SETTING N:25]\n",
            "Max validation accuracy: 0.6729999780654907\n",
            "[TRYING SETTING N:26]\n",
            "Max validation accuracy: 0.6869000196456909\n",
            "[TRYING SETTING N:27]\n",
            "Max validation accuracy: 0.6826000213623047\n",
            "[TRYING SETTING N:28]\n",
            "Max validation accuracy: 0.6735000014305115\n",
            "[TRYING SETTING N:29]\n",
            "Max validation accuracy: 0.6802999973297119\n",
            "[TRYING SETTING N:30]\n",
            "Max validation accuracy: 0.6779000163078308\n",
            "[TRYING SETTING N:31]\n",
            "Max validation accuracy: 0.6808000206947327\n",
            "[TRYING SETTING N:32]\n",
            "Max validation accuracy: 0.6696000099182129\n",
            "[TRYING SETTING N:33]\n",
            "Max validation accuracy: 0.6682000160217285\n",
            "[TRYING SETTING N:34]\n",
            "Max validation accuracy: 0.663100004196167\n",
            "[TRYING SETTING N:35]\n",
            "Max validation accuracy: 0.6682999730110168\n",
            "[TRYING SETTING N:36]\n",
            "Max validation accuracy: 0.6729999780654907\n",
            "[TRYING SETTING N:37]\n",
            "Max validation accuracy: 0.6794999837875366\n",
            "[TRYING SETTING N:38]\n",
            "Max validation accuracy: 0.6784999966621399\n",
            "[TRYING SETTING N:39]\n",
            "Max validation accuracy: 0.6776000261306763\n",
            "[TRYING SETTING N:40]\n",
            "Max validation accuracy: 0.6866000294685364\n",
            "[TRYING SETTING N:41]\n",
            "Max validation accuracy: 0.680899977684021\n",
            "[TRYING SETTING N:42]\n",
            "Max validation accuracy: 0.678600013256073\n",
            "[TRYING SETTING N:43]\n",
            "Max validation accuracy: 0.6782000064849854\n",
            "[TRYING SETTING N:44]\n",
            "Max validation accuracy: 0.6782000064849854\n",
            "[TRYING SETTING N:45]\n",
            "Max validation accuracy: 0.6784999966621399\n",
            "[TRYING SETTING N:46]\n",
            "Max validation accuracy: 0.6776000261306763\n",
            "[TRYING SETTING N:47]\n",
            "Max validation accuracy: 0.677299976348877\n",
            "[TRYING SETTING N:48]\n",
            "Max validation accuracy: 0.6647999882698059\n",
            "[TRYING SETTING N:49]\n",
            "Max validation accuracy: 0.6787999868392944\n",
            "[TRYING SETTING N:50]\n",
            "Max validation accuracy: 0.6700999736785889\n",
            "[TRYING SETTING N:51]\n",
            "Max validation accuracy: 0.6690999865531921\n",
            "[TRYING SETTING N:52]\n",
            "Max validation accuracy: 0.6786999702453613\n",
            "[TRYING SETTING N:53]\n",
            "Max validation accuracy: 0.6761000156402588\n",
            "[TRYING SETTING N:54]\n",
            "Max validation accuracy: 0.6751000285148621\n",
            "[TRYING SETTING N:55]\n",
            "Max validation accuracy: 0.6705999970436096\n",
            "[TRYING SETTING N:56]\n",
            "Max validation accuracy: 0.6725999712944031\n",
            "[TRYING SETTING N:57]\n",
            "Max validation accuracy: 0.6851999759674072\n",
            "[TRYING SETTING N:58]\n",
            "Max validation accuracy: 0.6736000180244446\n",
            "[TRYING SETTING N:59]\n",
            "Max validation accuracy: 0.6751999855041504\n",
            "[TRYING SETTING N:60]\n",
            "Max validation accuracy: 0.6748999953269958\n",
            "[TRYING SETTING N:61]\n",
            "Max validation accuracy: 0.6809999942779541\n",
            "[TRYING SETTING N:62]\n",
            "Max validation accuracy: 0.6794000267982483\n",
            "[TRYING SETTING N:63]\n",
            "Max validation accuracy: 0.6832000017166138\n",
            "END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L68DHcbNmMwS"
      },
      "source": [
        "The parameters of the fixed model we tried in the previous notebooks is somewhere in our params list. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5PnfbiEwwNZ"
      },
      "source": [
        "# LET'S FIND OUR FIXED MODEL ------\n",
        "def find_fixed():\n",
        "  for x,y in enumerate(params):\n",
        "    if (y==(32,32,64)):\n",
        "      return(x) \n",
        "fixed=find_fixed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7v85OAomXKU"
      },
      "source": [
        "Let's find the best results we obtained, on the validation set, with the grid search. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTZPwmrtkNVL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "377c912d-ff33-4226-f19a-b34e91600747"
      },
      "source": [
        "# RESULTS ------\n",
        "\n",
        "# BEST RESULTS GRID ---\n",
        "  # Which model \n",
        "index_model= np.argmax(np.max(score, 1))\n",
        "print(\"Combination that provided the highest accuracy:\", params[index_model])\n",
        "  # Which epoch \n",
        "index_epoch= np.argmax(score[index_model])\n",
        "  # retrieve\n",
        "best_accuracy = score[index_model][index_epoch]\n",
        "best_loss= loss[index_model][index_epoch]\n",
        "\n",
        "# BEST RESULTS FIXED ---\n",
        "# In the previous model we implemented (32, 64, 64 filters) => in our grid search it corresponds to index_fixed = 23\n",
        "index_fixed = fixed\n",
        "index= np.argmax(score[index_fixed])\n",
        "fixed_conv_best_accuracy= score[index_fixed][index]\n",
        "fixed_conv_best_loss= loss[index_fixed][index]\n",
        "\n",
        "# BEST RESULTS MLP (PREV NOTEBOOK) --- \n",
        "MLP_best_accuracy= 0.4865\n",
        "MLP_best_loss= 1.5456 \n",
        "\n",
        "results=pd.DataFrame(\n",
        "    {\"Row_names\":[\"Accuracy\", \"Loss\"], \n",
        "     \"MLP\":[MLP_best_accuracy,MLP_best_loss],\n",
        "     \"CONV\": [fixed_conv_best_accuracy,fixed_conv_best_loss],\n",
        "     \"GRID\":   [best_accuracy, best_loss]\n",
        "    }\n",
        ")\n",
        "results=results.set_index( \"Row_names\" )\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MLP</th>\n",
              "      <th>CONV</th>\n",
              "      <th>GRID</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row_names</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.4865</td>\n",
              "      <td>0.6721</td>\n",
              "      <td>0.686900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss</th>\n",
              "      <td>1.5456</td>\n",
              "      <td>0.6721</td>\n",
              "      <td>0.966773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              MLP    CONV      GRID\n",
              "Row_names                          \n",
              "Accuracy   0.4865  0.6721  0.686900\n",
              "Loss       1.5456  0.6721  0.966773"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PjeObIWmhi5"
      },
      "source": [
        "We obtained a 1.4 % increase in accuracy. Clearly changing only the number of filters didn't help much. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjbQKQw7op0j"
      },
      "source": [
        "## Random search hyperparameter for Convolutional neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwRBGxNlrVxy",
        "outputId": "4f0fce5d-ed69-4319-d48f-618844b89ba9"
      },
      "source": [
        "# RANDOM SEARCH ------\n",
        "n_layers=3 # How many CONVS\n",
        "params= [] \n",
        "for layer in range(n_layers):\n",
        "  params.append(np.linspace(start=16, stop=128, num=10)) # 16, 32, 48, 64, 128 => We try a wider space \n",
        "\n",
        "# Create all possible combinations  --- \n",
        "params=list(product(*params)) # Cartesian product => all combinations 4*4*4\n",
        "print(\"All possible combinations :\", len(params))\n",
        "\n",
        "# Sample from them --- \n",
        "indexes= np.random.choice(range(len(params)),20)\n",
        "random_params= [params[i] for i in indexes]\n",
        "\n",
        "print(\"RANDOMLY SAMPLED:\", len(random_params))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All possible combinations : 1000\n",
            "RANDOMLY SAMPLED: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnrI8K_Um2uz"
      },
      "source": [
        "There are a lot of possible combinations since we widen the space search, nonetheless, we restrained this space by sampling only 20 combinations. Hopefully one of them would yield good results. \n",
        "\n",
        "We fit every model again: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAzZ0_gNsfNf",
        "outputId": "c49e14fb-0ed8-4d2f-d14c-0a8e547c59cc"
      },
      "source": [
        "# RUN MODELS ------\n",
        "score=[]\n",
        "loss= []\n",
        "for i,param in enumerate(random_params):\n",
        "  print(f\"[TRYING SETTING N:{i}]\")\n",
        "  val_result,loss_result= grid_search(param)\n",
        "  print(f\"Max validation accuracy: {max(val_result)}\")\n",
        "  score.append(val_result)\n",
        "  loss.append(loss_result)\n",
        "print(\"END\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TRYING SETTING N:0]\n",
            "Max validation accuracy: 0.6590999960899353\n",
            "[TRYING SETTING N:1]\n",
            "Max validation accuracy: 0.6743999719619751\n",
            "[TRYING SETTING N:2]\n",
            "Max validation accuracy: 0.6692000031471252\n",
            "[TRYING SETTING N:3]\n",
            "Max validation accuracy: 0.6762999892234802\n",
            "[TRYING SETTING N:4]\n",
            "Max validation accuracy: 0.673799991607666\n",
            "[TRYING SETTING N:5]\n",
            "Max validation accuracy: 0.6744999885559082\n",
            "[TRYING SETTING N:6]\n",
            "Max validation accuracy: 0.6777999997138977\n",
            "[TRYING SETTING N:7]\n",
            "Max validation accuracy: 0.6708999872207642\n",
            "[TRYING SETTING N:8]\n",
            "Max validation accuracy: 0.6836000084877014\n",
            "[TRYING SETTING N:9]\n",
            "Max validation accuracy: 0.6733999848365784\n",
            "[TRYING SETTING N:10]\n",
            "Max validation accuracy: 0.6726999878883362\n",
            "[TRYING SETTING N:11]\n",
            "Max validation accuracy: 0.675599992275238\n",
            "[TRYING SETTING N:12]\n",
            "Max validation accuracy: 0.666700005531311\n",
            "[TRYING SETTING N:13]\n",
            "Max validation accuracy: 0.669700026512146\n",
            "[TRYING SETTING N:14]\n",
            "Max validation accuracy: 0.6802999973297119\n",
            "[TRYING SETTING N:15]\n",
            "Max validation accuracy: 0.6620000004768372\n",
            "[TRYING SETTING N:16]\n",
            "Max validation accuracy: 0.6743999719619751\n",
            "[TRYING SETTING N:17]\n",
            "Max validation accuracy: 0.6847000122070312\n",
            "[TRYING SETTING N:18]\n",
            "Max validation accuracy: 0.6805999875068665\n",
            "[TRYING SETTING N:19]\n",
            "Max validation accuracy: 0.6848999857902527\n",
            "END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25DQSEAVnMgu"
      },
      "source": [
        "We bind the new best results on the validation set in our table to compare this method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oule_7gGsnkv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "3bf7210a-564f-45cc-ef38-813085a4209a"
      },
      "source": [
        "# BEST RESULTS RANDOM ------ \n",
        "# Which model --- \n",
        "index_model=np.argmax(np.max(score,1))\n",
        "print(\"Combination that provided the highest accuracy:\", params[index_model])\n",
        "# Which epoch --- \n",
        "index_epoch=np.argmax(score[index_model])\n",
        "# Retrieve --- \n",
        "best_accuracy = score[index_model][index_epoch]\n",
        "best_loss= loss[index_model][index_epoch]\n",
        "\n",
        "to_append= [best_accuracy,best_loss ]\n",
        "# COLBIND \n",
        "results[\"RANDOM\"]= to_append\n",
        "results"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Combination that provided the highest accuracy: (16.0, 28.444444444444443, 128.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row_names</th>\n",
              "      <th>MLP</th>\n",
              "      <th>CONV</th>\n",
              "      <th>GRID</th>\n",
              "      <th>RANDOM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>0.4865</td>\n",
              "      <td>0.672100</td>\n",
              "      <td>0.686900</td>\n",
              "      <td>0.684900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Loss</td>\n",
              "      <td>1.5456</td>\n",
              "      <td>1.451947</td>\n",
              "      <td>0.966773</td>\n",
              "      <td>0.962091</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Row_names     MLP      CONV      GRID    RANDOM\n",
              "0  Accuracy  0.4865  0.672100  0.686900  0.684900\n",
              "1      Loss  1.5456  1.451947  0.966773  0.962091"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fxoGZ5gnyqf"
      },
      "source": [
        "Grid search and a random search of a few hyperparameters improve our results but not significantly (at our current results the change was small, since we are still underfitting on new data). **We achieved a 1.6 percentage point increase in accuracy** but we were definitively hoping for more. This is specially the case because of the time it took to test all hyperparameters. "
      ]
    }
  ]
}